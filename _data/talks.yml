- type: Talks (2022-2023)
  members:
    - speaker: Chao Gao (University of Chicago)
      date: October 17, 2022 
      title: Iterative Algorithm for Discrete Structure Recovery
      abstract: We propose a general modeling and algorithmic framework for discrete structure recovery that can be applied to a wide range of problems. Under this framework, we are able to study the recovery of clustering labels, ranks of players, signs of regression coefficients, cyclic shifts, and even group elements from a unified perspective. A simple iterative algorithm is proposed for discrete structure recovery, which generalizes methods including Lloyd's algorithm and the power method. A linear convergence result for the proposed algorithm is established in this paper under appropriate abstract conditions on stochastic errors and initialization. We illustrate our general theory by applying it on several representative problems, (1) clustering in Gaussian mixture model, (2) approximate ranking, (3) sign recovery in compressed sensing, (4) multireference alignment, and (5) group synchronization, and show that minimax rate is achieved in each case.
      bio: Chao Gao is an Assistant Professor in Statistics at University of Chicago
      link: https://arxiv.org/pdf/1911.01018.pdf
    - speaker: Ye Zhang (University of Pennsylvania)
      date: October 24, 2022
      title: Sharp Theoretical Analysis of Spectral Methods in Clustering and Synchronization
      abstract: Spectral methods are simple but powerful approaches for extracting information from noisy data and have been widely used in various applications. In this talk, we demystify the success of spectral methods by establishing sharp theoretical guarantees for their performance in clustering and synchronization. (1) The first part of the talk is about a novel singular subspace perturbation analysis for spectral clustering. We consider two arbitrary matrices where one is a leave-one-column-out submatrix of the other one and establish a new perturbation upper bound for the distance between their corresponding singular subspaces. Powered by this tool, we obtain an explicit exponential error rate for the performance of spectral clustering in sub-Gaussian mixture models. (2) The second part of the talk is about the exact minimax optimality of a spectral method in the phase synchronization problem with additive Gaussian noises and incomplete data. We prove that it achieves the minimax lower bound of the problem with a matching leading constant under a squared l2 loss. This shows that the spectral method has the same performance as more sophisticated procedures including maximum likelihood estimation, generalized power method, and semidefinite programming, when consistent parameter estimation is possible.
      link: https://arxiv.org/abs/2205.14855 
      bio: Anderson Ye Zhang is an assistant professor in the Department of Statistics and Data Science at the University of Pennsylvania. Before joining Penn, he was a William H. Kruskal Instructor in Department of Statistics at the University of Chicago. He completed his Ph.D. in Statistics and Data Science at Yale University. His research includes spectral analysis, network analysis, clustering, ranking, and synchronization. 
    - speaker: Chao Zhang (University of Oxford)
      date: October 31, 2022
      title:  Volatility forecasting with machine learning and intraday commonality & Forecasting Realized Covariances via Graphs
      abstract: (Volatility forecasting) We apply machine learning models to forecast intraday realized volatility (RV), by exploiting commonality in intraday volatility via pooling stock data together, and by incorporating a proxy for the market volatility. Neural networks dominate linear regressions and tree models in terms of performance, due to their ability to uncover and model complex latent interactions among variables. Our findings remain robust when we apply trained models to new stocks that have not been included in the training set, thus providing new empirical evidence for a universal volatility mechanism among stocks. Finally, we propose a new approach to forecasting one-day-ahead RVs using past intraday RVs as predictors, and highlight interesting diurnal effects that aid the forecasting mechanism. The results demonstrate that the proposed methodology yields superior out-of-sample forecasts over a strong set of traditional baselines that only rely on past daily RVs.
      link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4022147
    - speaker: Yuxin Chen  (University of Pennsylvania)
      date: November 7, 2022
      title: Inference and Uncertainty Quantification for Nonconvex Low-Rank Models
      abstract: Many high-dimensional problems involve reconstruction of a low-rank matrix from incomplete and corrupted observations. Despite substantial progress in designing efficient estimation algorithms, it remains largely unclear how to assess the uncertainty of the obtained low-rank estimates, and how to construct valid yet short confidence intervals for the unknown low-rank matrix.  In this talk, I will discuss how to perform inference and uncertainty quantification for two examples of low-rank models, (1) heteroskedastic PCA with missing data, and (2) noisy matrix completion. For both problems,  we identify statistically efficient estimators that admit non-asymptotic distributional characterizations, which in turn enable optimal construction of confidence intervals for, say, the unseen entries of the low-rank matrix of interest.  All this is accomplished by a powerful leave-one-out analysis framework that originated from probability and random matrix theory. This is based on joint work with Yuling Yan, Cong Ma, and Jianqing Fan. 
      link: https://arxiv.org/abs/2107.12365
      bio: Yuxin Chen is currently an associate professor in the Department of Statistics and Data Science at the University of Pennsylvania. Before joining UPenn, he was an assistant professor of electrical and computer engineering at Princeton University. He completed his Ph.D. in Electrical Engineering at Stanford University, and was also a postdoc scholar at Stanford Statistics. His current research interests include high-dimensional statistics, nonconvex optimization, and reinforcement learning. He has received the Alfred P. Sloan Research Fellowship, the ICCM best paper award (gold medal), the AFOSR and ARO Young Investigator Awards, the Google Research Scholar Award, and was selected as a finalist for the Best Paper Prize for Young Researchers in Continuous Optimization. He has also received the Princeton Graduate Mentoring Award. 
    - speaker: Jakob Albers  (University of Oxford)
      date: November 14, 2022
      title: Fragmentation, Price Formation, and Cross-Impact in Bitcoin Markets
      abstract: In light of micro-scale inefficiencies induced by the high degree of fragmentation of the Bitcoin trading landscape, we utilize a granular data set comprised of orderbook and trades data from the most liquid Bitcoin markets, in order to understand the price formation process at sub-1 second time scales. To achieve this goal, we construct a set of features that encapsulate relevant microstructural information over short lookback windows. These features are subsequently leveraged first to generate a leader-lagger network that quantifies how markets impact one another, and then to train linear models capable of explaining between 10% and 37% of total variation in 500ms future returns (depending on which market is the prediction target). The results are then compared with those of various PnL calculations that take trading realities, such as transaction costs, into account. The PnL calculations are based on natural taker strategies (meaning they employ market orders) that we associate to each model. Our findings emphasize the role of a market’s fee regime in determining its propensity to being a leader or a lagger, as well as the profitability of our taker strategy. Taking our analysis further, we also derive a natural maker strategy (i.e., one that uses only passive limit orders), which, due to the difficulties associated with backtesting maker strategies, we test in a real-world live trading experiment, in which we turned over 1.5 million USD in notional volume. Lending additional confidence to our models, and by extension to the features they are based on, the results indicate a significant improvement over a naive benchmark strategy, which we also deploy in a live trading environment with real capital, for the sake of comparison.
      link: https://www.tandfonline.com/doi/full/10.1080/1350486X.2022.2080083     
    - speaker: Qinkai Chen (Ecole Polytechnique) 
      date: November 22, 2022 (Tuesday 2-3pm)
      title: Multivariate Realized Volatility Forecasting with Graph Neural Networks
      abstract: Financial economics and econometrics literature demonstrate that the limit order book data is useful in predicting short-term volatility in stock markets. In this paper, we are interested in forecasting short- term realized volatility in a multivariate approach based on limit order book data and relational stock market networks. To achieve this goal, we introduce Graph Transformer Network for Volatility Forecasting. The model allows combining limit order book features and a large number of temporal and cross-sectional relations from different sources. Through experiments based on about 500 stocks from S&P 500 index, we find a better performance for our model than for other benchmarks.
    - speaker: Rian Dolphin (University College Dublin)
      date: November 28, 2022
      title: A Multimodal Embedding-Based Approach to Industry Classification in Financial Markets
      abstract: Industry classification schemes provide a taxonomy for segmenting companies based on their business activities. They are relied upon in industry and academia as an integral component of many types of financial and economic analysis. However, even modern classification schemes have failed to embrace the era of big data and remain a largely subjective undertaking prone to inconsistency and misclassification. To address this, we propose a multimodal neural model for training company embeddings, which harnesses the dynamics of both historical pricing data and financial news to learn objective company representations that capture nuanced relationships. We explain our approach in detail and highlight the utility of the embeddings through several case studies and application to the downstream task of industry classification.
      link: https://arxiv.org/pdf/2211.06378.pdf
    - speaker: Julien Guyon (Ecole des Ponts ParisTech) 
      date:  December 5, 2022
      title: Volatility Is (Mostly) Path-Dependent
      abstract: We learn from data that volatility is mostly path-dependent. Up to 90% of the variance of the implied volatility of equity indexes is explained endogenously by past index returns, and up to 65% for (noisy estimates of) future daily realized volatility. The path-dependency that we uncover is remarkably simple because a linear combination of a weighted sum of past daily returns and the square root of a weighted sum of past daily squared returns with different time-shifted power-law weights capturing both short and long memory. This simple model, which is homogeneous in volatility, is shown to consistently outperform existing models across equity indexes and train/test sets for both implied and realized volatility. It suggests a simple continuous-time path-dependent volatility (PDV) model that may be fed historical or risk-neutral parameters. The weights can be approximated by superpositions of exponential kernels to produce Markovian models. In particular, we propose a 4-factor Markovian PDV model which captures all the important stylized facts of volatility, produces very realistic price and volatility paths, and jointly fits SPX and VIX smiles remarkably well. We thus show, for the first time, that a continuous-time Markovian parametric stochastic volatility (actually, PDV) model can practically solve the joint S&P 500/VIX smile calibration problem.
    - speaker: Ding Yi (University of Macau)
      date: December 12, 2022
      title: Stock co-jump networks 
      abstract: We propose a Degree-Corrected Block Model with Dependent Multivariate Poisson edges (DCBM-DMP) to study stock co-jump dependency. To estimate the community structure, we extend the SCORE algorithm in Jin (2015) and develop a Spectral Clustering On Ratios-of-Eigenvectors for networks with Dependent Multivariate Poisson edges (SCORE-DMP) algorithm. We prove that SCORE-DMP enjoys strong consistency in community detection. Empirically, using high-frequency data of S&P 500 constituents, we construct two co-jump networks according to whether the market jumps and find that they exhibit different community features than GICS. We further show that the co-jump networks help in stock return prediction. 
    - speaker: Kevin Huynh (University of Basel)
      date: December 19, 2022
      title: Asymmetric Autoencoders for Factor-Based Covariance Matrix Estimation
      abstract: Estimating high dimensional covariance matrices for portfolio optimization is challenging because the number of parameters to be estimated grows quadratically in the number of assets. When the matrix dimension exceeds the sample size, the sample covariance matrix becomes singular. A possible solution is to impose a (latent) factor structure for the cross-section of asset returns as in the popular capital asset pricing model. Recent research suggests dimension reduction techniques to estimate the factors in a data-driven fashion. We present an asymmetric autoencoder neural network-based estimator that incorporates the factor structure in its architecture and jointly estimates the factors and their loadings. We test our method against well established dimension reduction techniques from the literature and compare them to observable factors as benchmark in an empirical experiment using stock returns of the past five decades. Results show that the proposed estimator is very competitive, as it significantly outperforms the benchmark across most scenarios. Analyzing the loadings, we find that the constructed factors are related to the stocks’ sector classification.
    - speaker: Corentin Vande Kerckhove (UCLouvain)
      date: January 12, 2022 (Thursday)
      title: Predictive Analytics using social media data: latent variables estimates for sales surprise prediction
      abstract: In the last decade, the arrival of new forms of social media has drastically increased the amount of personal data generated online. The massive amount of data available has shown a lot of opportunities for industries and research. In particular, increasing numbers of quantitative investors start to rely on alternative data to adapt their position in the market. However, it is still unclear whether aggregated online data could generate excess returns in active investing and allow refining positions on the stock market. In the present talk, we propose to tackle the question by focusing on three underlying themes. First, we will introduce one of the first viable approaches to the estimation of individual-level ideological positions derived from social media content. Second, we will show how a consensus model can be used to predict opinion evolution in online collective behaviour and how the "wisdom of the crowd" relates to group influence. Finally, we will explore whether aggregated opinion signals have potential to predict financial fundamentals and build an edge on the market.
    - speaker: Ajim Uddin (New Jersey Institute of Technology)
      date: January 23, 2022
      title: Attention Based Dynamic Graph Neural Network for Asset Pricing
      abstract: Recent studies suggest that networks among firms (sectors) play an essential role in asset pricing. However, it is challenging to capture and investigate the implications of networks due to the continuous evolution of networks in response to market micro and macro changes. This paper combines two state-of-the-art machine learning techniques to develop an end-to-end graph neural network model and shows its applicability in asset pricing. First, we apply the graph attention mechanism to learn dynamic network structures of the equity market over time and then use a recurrent convolutional neural network to diffuse and propagate firms fundamental information into the learned networks. Our model is efficient in both return prediction and portfolio performance. The result persists in different sensitivity tests and simulated data. We also show that the dynamic network learned from our model is able to capture major market events over time.
    - speaker: Cédric Poutré (University of Montreal)
      date: February 13, 2023
      title: The Profitability of Lead-Lag Arbitrage at High-Frequency
      abstract: Any lead-lag effect in an asset pair implies the future returns on the lagging asset have the potential to be predicted from past and present prices of the leader, thus creating statistical arbitrage opportunities. We utilize robust lead-lag indicators to uncover the origin of price discovery and we propose an econometric model exploiting that effect with level 1 data of limit order books (LOB). We also develop a high-frequency trading strategy based on the model predictions to capture arbitrage opportunities. The framework is then evaluated on six months of DAX 30 cross-listed stocks' LOB data obtained from three European exchanges in 2013 -- Xetra, Chi-X, and BATS. We show that a high-frequency trader can profit from lead-lag relationships because of predictability, even when trading costs, latency, and execution-related risks are considered. Keywords - Lead-lag relationship, High-frequency trading, Statistical arbitrage, Limit order book, Cross-listed stocks, Econometric models.
      link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4223813
    - speaker: Melanie Schienle  (Karlsruhe Institute of Technology KIT)
      date: February 20, 2023
    - speaker: Agostino Capponi (Columbia University) 
      date: February 27, 2023
    - speaker: Petter Kolm (NYU) 
      date: February, 2023  
      

- type: Past Talks
  members:
    - speaker: Andreas Lehrmann
      date: June 13, 2022
      title: "Continuous-time Modelling of Irregular Time-Series"
      abstract: "Globally, capital markets have gone through a paradigm shift towards complete automation through artificial intelligence, turning it into a highly competitive area at the intersection of statistical models from various branches of machine learning. A principled understanding of the interactions between statistical models that operate in a common environment will soon be a key success factor for leaders in the field. In this talk I will first discuss the unique challenges of capital markets through the lens of machine learning and then provide an overview how Borealis AI addresses them from an atomistic and a holistic point of view. In the second part of the talk I will focus on our recent work on continuous-time modeling of irregular time-series and describe an expressive differential deformation of the Wiener process using neural ordinary differential equations. Finally, we will see how an augmentation of this model with a latent process driven by a stochastic differential equation can further increase the flexibility of this system and allows us to capture non-Markovian dynamics."
      bio: "Andreas Lehrmann is a machine learning researcher at Borealis AI. Previously, he held postdoctoral positions at Facebook Reality Labs and Disney Research. He received his Ph.D. at ETH Zurich and the Max-Planck-Institute for Intelligent Systems under a Microsoft Research scholarship."    
      link: https://proceedings.neurips.cc/paper/2021/file/2983e3047c0c730d3b7c022584717f3f-Paper.pdf
    - speaker: Chris Musco 
      date: June 6, 2022
      title: "Structured Covariance Estimation"
      abstract: "How many samples are needed to accurately learn the covariance matrix, C, of a distribution over d-dimensional vectors? In modern data applications where d is large, the answer is often unacceptably high: the sample complexity of covariance learning inherently depends poorly on dimension. In this talk I will discuss efforts to address this issue by designing data collection methods and learning algorithms which reduce complexity by leveraging a priori knowledge about the covariance matrix. Specifically, I will discuss the setting when C is known to have Toeplitz structure. Toeplitz covariance matrices arise in many applications, from time series analysis, to wireless communications, to medical imaging. In many of these applications, data collection is expensive, so reducing sample complexity is an important goal. We will start by taking a fresh look at classical and widely used algorithms, including methods based on selecting samples according to a sparse ruler. Then, I will introduce a novel sampling and estimation strategy that improves on existing methods in many settings. Our new approach for learning Toeplitz structured covariance utilizes tools from random matrix sketching, non-linear approximation theory, and sparse Fourier transform algorithms. It fits into a broader line of work which seeks to address problems in active learning using tools from theoretical computer science and randomized numerical linear algebra."
      bio: "Chris Musco is an Assistant Professor at New York University in the Tandon School of Engineering"
    - speaker: Lisa Goldberg 
      date: May 30, 2022 
      title:  James Stein for Eigenvectors
      abstract: "Estimated covariance matrices are widely used to construct portfolios with variance-minimizing optimization, yet the embedded sampling error produces portfolios with systematically underestimated variance. This effect is especially severe when the number of securities greatly exceeds the number of observations. In this high dimension low sample size (HL) regime, we show that a dispersion bias in the leading eigenvector of the estimated covariance matrix is a material source of distortion in the minimum variance portfolio. We correct the bias with the data-driven GPS (Global Positioning System) shrinkage estimator, which improves with the size of the market, and which is structurally identical to the James Stein estimator for a collection of averages. We illustrate the power of the GPS estimator with a numerical example, and conclude with open problems that have emerged from our research."
      bio: Lisa Goldberg is Professor of the Practice of Economics at University of California Berkeley. She is the co-director of the Berkeley Consortium for Data Analytics in Risk. She is Head of Research at Aperio Group, now part of BlackRock. 
      link: https://cdar.berkeley.edu/sites/default/files/publications/the_dispersion_bias_1.2022.pdf 
    - speaker: Vincent Tan
      date: May 23, 2022
      title: "Canonical Portfolios: Optimal Asset and Signal Combination"
      link: https://arxiv.org/abs/2202.10817 
    - speaker: Anish Agarwal  
      date: May 16, 2022
      title: "Causal Inference for Social and Engineering Systems"
      abstract: "What will happen to Y if we do A? A variety of meaningful social and engineering questions can be formulated this way: What will happen to a patient’s health if they are given a new therapy? What will happen to a country’s economy if policy-makers legislate a new tax? What will happen to a data center’s latency if a new congestion control protocol is used? We explore how to answer such counterfactual questions using observational data---which is increasingly available due to digitization and pervasive sensors---and/or very limited experimental data. The two key challenges are: (i) counterfactual prediction in the presence of latent confounders; (ii) estimation with modern datasets which are high-dimensional, noisy, and sparse. The key framework we introduce is connecting causal inference with tensor completion. In particular, we represent the various potential outcomes (i.e., counterfactuals) of interest through an order-3 tensor. The key theoretical results presented are: (i) Formal identification results establishing under what missingness patterns, latent confounding, and structure on the tensor is recovery of unobserved potential outcomes possible. (ii) Introducing novel estimators to recover these unobserved potential outcomes and proving they are finite-sample consistent and asymptotically normal. The efficacy of our framework is shown on high-impact applications. These include working with: (i) TaurRx Therapeutics to identify patient sub-populations where their therapy was effective. (ii) Uber Technologies on evaluating the impact of driver engagement policies without running an A/B test. (iii) The Poverty Action Lab at MIT to make personalized policy recommendations to improve childhood immunization rates across villages in Haryana, India. Finally, we discuss connections between causal inference, tensor completion, and offline reinforcement learning."
      bio: "Anish is currently a postdoctoral fellow at the Simons Institute at UC Berkeley. He did his PhD at MIT in EECS where he was advised by Alberto Abadie, Munther Dahleh, and Devavrat Shah. His research focuses on designing and analyzing methods for causal machine learning, and applying it to critical problems in social and engineering systems. He currently serves as a technical consultant to TauRx Therapeutics and Uber Technologies on questions related to experiment design and causal inference. Prior to the PhD, he was a management consultant at Boston Consulting Group. He received his BSc and MSc at Caltech."
      link: https://arxiv.org/abs/2109.15154
      recording: https://www.youtube.com/watch?v=MK5EXE7MkEk
    - speaker: Lorenzo Lucchese 
      date: May 9, 2022
      title: "Deep Limit Order Books"
    - speaker: Alvaro Arroyo
      date: May 2, 2022
      title: "Estimation Theory with Spectral Methods"
    - speaker: Qiong Wu
      date: April 11, 2022
      title: "Embedding Algorithms for Cross-Asset Equity Models"
    - speaker: Parley Ruogu Yang
      date: March 28, 2022
      title: "Adaptive Learning on Time Series: Methods and Financial Applications"
    - speaker: Christopher Policastro
      date: May 14, 2022
      title: "Singular Spectrum Analysis"
    - speaker:  Nicolas Cassia Terrazo, Qi Jin, Alexey Kapustin, Zhi Qi
      date: March 7, 2022
      title: "Co-jumping Behaviour in Time-Series and Financial Networks"
    - speaker: Adrien Hardy 
      date: February 28, 2022
      title: "Learning Factors Data Challenge"
    - speaker: Alik Sokolov
      date: February 21, 2022
      title: "ESG Case Studies"
    - speaker: Jianian Wang 
      date: February 14, 2022
      title: "A Review on Graph Neural Network Methods in Financial Applications"
    - speaker: Mihai Cucuringu
      date: February 7, 2022
      title: "Introduction to the Mechanics of Limit Order Books"
    - speaker: Milena Vuletic 
      date: January 24, 2022
      title: "Financial Time-Series Forecasting via GANs"
    - speaker:  Vincent Tan 
      date: January 17, 2022
      title: "Large covariance estimation, portfolio selection"
    - speaker:  Deborah Miori
      date: January 10, 2022
      title: " Fund2Vec: Mutual Funds Similarity using Graph Learning"
    - speaker: Yutong Lu 
      date: January 3, 2022
      title: "Network Effects in Financial High-Frequency Data"
    - speaker: Christopher Policastro
      date: December 20, 2022
      title: "Synopsis of MLECON Workshop"
    - speaker: Stefanos Bennett 
      date: December 13, 2022
      title: "Lead-lag detection and network clustering for multivariate time series with an application to the US equity market"
    - speaker: Nikolas Michael 
      date: December 6, 2022
      title: "Option Volume Imbalance as a predictor for spot market returns"
    - speaker: Felix Prenzel
      date: November 29, 2022
      title: "Analysis and Modelling of Client Order Flow in Limit Order Markets"
    - speaker:  Chao Zhang  
      date: November 22, 2022
      title: "Limit Order Books, Order Flow Imbalances, Price Impact, Lead-Lag Effects"
